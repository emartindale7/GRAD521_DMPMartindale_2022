# Research Overview

The research covered in this plan is to develop a machine learning model that can accurately classify the sleep states of mice based on noninvasively collected data. The mice will be observed while they are in an environment that they are familiar with. They will be observed using electric field sensors which can measure movement of the mice from outside of their cage. This data will be used to classify periods that the mice are resting into three stages, wake, REM, and NREM. The research question that this project will be answering is "what features of the electric field signal are important to accurately classify sleep stages?". 

# Data description

For this research project, data will need to be collected using electric field sensors and from camera above the cages. Video from the camera will be used to verify sleep/ wake states of the mice that are scored using the electric field data. The electric field sensor and video data will be collected by observing the mice in their cages without any outside interference or distractions to see how the mice act when they are not stressed. The original data files of electric field data are saved as proprietary .abf files and the video files are saved as .avi files. 

A subset of data is manually scored by using Spike2 software to view the abf files and ELAN software to view the video files. Both programs are then used to produce annotations for the electric field sensor or camera data and output these annotations, or scores, as mat files. MATLAB scripts have been written to then process the abf files and mat files into combined mat files with data organized into 10 second epochs. This can then be further processed with another MATLAB script to produce a single csv of extracted features from many input files. Python scripts then take this csv as input to train machine learning models with. The MATLAB and python scripts are being developed throughout this project to produce an acceptable classification model and will be managed with this data management plan. 

The electric field dataset is estimated to be between 0.5 and 1 GB and the combined electric field and scoring dataset is estimated to be about 1 GB. The video dataset is estimated to be about 100 GB. The processed data is estimated to be about 3.5 GB. The total size of the datasets is then estimated to be about 115 GB.

# Roles and responsibilities

Everyone involved in data collection and processing is responsible for implementing the data management plan. The PI for the lab is responsible for making sure that there is a data management plan and that people are following it. The PI will also be in charge of making sure the data is being properly archived, preserved and also making sure to protect sensitive and protected data, and overall access control of all data. The lead grad student for each project will be in charge of coming up with a consistent data organization plan, making sure the proper metadata is being generated and recorded, and the data management for that project. All other grad students involved in the project will hep to ensure instruments are in calibration and have proper maintenance recorded, creating and maintaining useful software and code, and working on data analysis. Anyone generating or collecting data is responsible for quality control, though the lead grad student and PI are responsible for overall quality control of the project.

The data is not sensitive or confidential according to OSUâ€™s policy. The unrestricted data stills needs to be in a secure location though to make sure data is not lost. This will be done by using an Oregon State approved data storage location, especially for any data that will be remotely accessible.

Data will be first collected and stored on the lab computer that runs the equipment. When a set of data has been collected it will be copied to an external hard drive to be transferred and kept with the rest of the project data. For data processing and analysis, copies of the data will be transferred to a workstation to perform any processing and analysis needed. The original files will not be changed and the newly created files will need to be copied to the overall project storage location. If this data is going to be accessed from multiple computers for these steps copies may be saved to an Oregon State cloud service but then any generated data will need to be saved in the same location as the original data. 

# Data standards and metadata

Data for this project is organized using a file naming convention and file structure. Electric field files and video files are collected and saved to project specific folders that are named for the experiment, the date, the cage, and the animals. The individual files follow this same naming convention to ensure they are not misplaced and data is not lost. When the data is to be manually analyzed, the raw files are loaded into a program and the labeled and processed output is saved as a new filetype and named with the same naming convention. The raw and manually processed data can then be input into the software that is being developed for this project and the output will include the same name, but with a signifier appended to the end to denote at what stage of the automatic analysis the output files are from.

Git version control is used to record the different iterations of software developed for this project. A local git repository will be used while the software and analysis tools are still in development, but when the project is finished, this repository will be published along with the information collected. This version control will also be used to record the documentation files that are written to explain the software analysis and describe the necessary metadata.

There is not currently a metadata standard being used for this project. A current standard that would likely be applicable for this project is the [ISA-Tab](http://isatab.sourceforge.net/docs/ISA-TAB_release-candidate-1_v1.0_24nov08.pdf) standard. This standard guides organization of file structure so that complex information from a specific assay or test can be related back to a study and that study can be related back to the larger investigation.

# Storage and security

The data for this research project is stored and backed up with external hard drives in two different places. The backup process is then currently done manually and does not involve any specific programs or a network drive. Any data that is saved to a cloud system should also be backed up to a hard drive so that the lab retains all of the data for the project. The cloud folders for any ongoing research are also owned by the lab PI so that if any data would not have been backed up yet, they will not be lost when a student graduates.

# Access and data sharing

The sharing and use of the data is not restricted by any factors. The data will be licensed under CC BY  so that anyone can use the data as long as they give credit to the researchers that collected the data. Data will be available in the associated paper under supplementary data. The paper will also provide a link to where the data is stored in the [Zenodo](https://zenodo.org/) repository. If there are problems accessing data from the repository or from the supplemental data with the paper, contact information given in the paper can be used to notify the lab of the problem and directly request copies of the data. 

GitHub will be used to publish the code repository of the MATLAB and python scripts, which will also be linked to in the paper. This code repository will also be integrated into the Zenodo repository according to the archiving and preservation section of this plan. 

# Archiving and preservation

The data itself will be preserved with the lab in an archive, as well as preserved in the public repository that it is submitted to. These preservation methods will need to retain the data for at least 5 years. Code for the project associated with the data will be submitted to GitHub, as well as having a local git repository stored in the lab's archive. This will also need to be stored for 5 years. The data repository and GitHub repository will both allow public access and access through request to the lab will be a secondary method of access to archive data and code. 
